{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for CWGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "\n",
    "def split_timestamp(pth) -> pd.DataFrame:\n",
    "    df = pd.read_csv(pth)\n",
    "\n",
    "    # consider chinese holiday\n",
    "    # if self.chinese_holiday:\n",
    "    #     df[\"holiday\"] = 0\n",
    "    #     for j in range(len(df)):\n",
    "    #         temp = df[\"ds\"][j]\n",
    "    #         date_time = datetime.datetime.strptime(temp,\n",
    "    #                                                 \"%Y-%m-%d %H:%M:%S\")\n",
    "    #         if not is_workday(date_time):\n",
    "    #             df[\"holiday\"] = 1\n",
    "\n",
    "    df_time = df[\"ds\"].str.split(' ', expand=True)\n",
    "    df_date = df_time[0].str.split('/', expand=True)\n",
    "    df_date.columns = [\"year\", \"month\", \"date\"]\n",
    "    df_hour = df_time[1].str.split(':', expand=True)\n",
    "    df_hour.columns = [\"hour\", \"minute\"]\n",
    "    # if self.chinese_holiday:\n",
    "    #     df_all_time = pd.concat(\n",
    "    #         [df_date, df_hour, df[[\"holiday\"]], df[[\"value\"]]], axis=1)\n",
    "    # else:\n",
    "    df_all_time = pd.concat([df_date, df_hour, df[[\"value\"]]], axis=1)\n",
    "    df_all_time = df_all_time.astype(\"float\")\n",
    "    # df_all_time.drop(\"second\", axis=1, inplace=True)\n",
    "    # df_all_time.to_csv(f\"{self.file_pth[:-4]}_split.csv\", index=False)\n",
    "    return df_all_time\n",
    "\n",
    "def scale(train_data, val_data, test_data):\n",
    "    # scaler = StandardScaler()\n",
    "    # scaled_train = scaler.fit_transform(train_data)\n",
    "    # if val_data is not None:\n",
    "    #     scaled_val = scaler.transform(val_data)\n",
    "    # else:\n",
    "    #     scaled_val = None\n",
    "    # scaled_test = scaler.transform(test_data)\n",
    "    results = {\n",
    "        \"train_ds\": train_data,\n",
    "        \"val_ds\": val_data,\n",
    "        \"test_ds\": test_data,\n",
    "        \"scaler\": 0\n",
    "    }\n",
    "    # results = {\n",
    "    #     \"train_ds\": scaled_train,\n",
    "    #     \"val_ds\": scaled_val,\n",
    "    #     \"test_ds\": scaled_test,\n",
    "    #     \"scaler\": scaler\n",
    "    # }\n",
    "    pickle.dump(results, open('loggings/data_preprocess.pkl', 'wb'))\n",
    "\n",
    "\n",
    "pth = \"data/PV_jz.csv\"\n",
    "df = split_timestamp(pth)\n",
    "df.drop([\"year\", \"value\", \"minute\", \"hour\"], axis=1, inplace=True)\n",
    "print(df.head(5))\n",
    "pv_reshape = np.loadtxt(\"data/PV_jz_reshape.csv\", delimiter=\",\")\n",
    "\n",
    "df = df.values\n",
    "\n",
    "results = np.zeros([pv_reshape.shape[0], pv_reshape.shape[1] + df.shape[1]])\n",
    "start = 0\n",
    "for i in range(len(pv_reshape)):\n",
    "    # print(pv_reshape[i, :])\n",
    "    # print(df[start, :])\n",
    "    # print(np.concatenate([pv_reshape[i, :], df[start, :]], axis=0))\n",
    "    results[i, :] = np.concatenate([pv_reshape[i, :], df[start, :]], axis=0)\n",
    "    start = start + 96\n",
    "\n",
    "print(results)\n",
    "# results = pd.DataFrame(results)\n",
    "\n",
    "pv_train, pv_test = train_test_split(results, test_size=0.2, shuffle=False)\n",
    "scale(pv_train, None, pv_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "\n",
    "def scale(train_data, val_data, test_data):\n",
    "    # scaler = StandardScaler()\n",
    "    # scaled_train = scaler.fit_transform(train_data)\n",
    "    # if val_data is not None:\n",
    "    #     scaled_val = scaler.transform(val_data)\n",
    "    # else:\n",
    "    #     scaled_val = None\n",
    "    # scaled_test = scaler.transform(test_data)\n",
    "    results = {\n",
    "        \"train_ds\": train_data,\n",
    "        \"val_ds\": val_data,\n",
    "        \"test_ds\": test_data,\n",
    "        \"scaler\": 0\n",
    "    }\n",
    "    # results = {\n",
    "    #     \"train_ds\": scaled_train,\n",
    "    #     \"val_ds\": scaled_val,\n",
    "    #     \"test_ds\": scaled_test,\n",
    "    #     \"scaler\": scaler\n",
    "    # }\n",
    "    pickle.dump(results, open('loggings/data_preprocess.pkl', 'wb'))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/PV_jz.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "pv = df.values[:int(len(df) / 96) * 96, -1]\n",
    "print(pv.shape)\n",
    "pv = pv.reshape([-1, 96])\n",
    "print(pv.shape)\n",
    "pv_train, pv_test = train_test_split(pv, test_size=0.2, shuffle=False)\n",
    "scale(pv_train, None, pv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mydata = pickle.load(open('loggings/data_preprocess.pkl', 'rb'))\n",
    "# scaler = mydata[\"scaler\"]\n",
    "test_ds = mydata[\"test_ds\"]\n",
    "generator = torch.load(\"loggings/generator.pth\")\n",
    "generator.eval()\n",
    "\n",
    "select = 51\n",
    "target = test_ds[select][:-2]\n",
    "cond = test_ds[select][-2:].reshape(1, -1)\n",
    "# target = torch.from_numpy(target).float().cuda()\n",
    "cond = torch.from_numpy(cond).float().cuda()\n",
    "\n",
    "num = 100\n",
    "dist = 99999999\n",
    "idx = 0\n",
    "record = []\n",
    "for i in range(num):\n",
    "    z = torch.normal(0, 1, [1, 96]).cuda()\n",
    "    \n",
    "    # print(z)\n",
    "    # break\n",
    "    y_hat = generator(z, cond)\n",
    "    y_hat = y_hat.detach().cpu().numpy().reshape(target.shape)\n",
    "    y_hat = y_hat.astype(float)\n",
    "    if np.linalg.norm(y_hat - target) < dist:\n",
    "        dist = np.linalg.norm(y_hat - target)\n",
    "        idx = i\n",
    "    record.append(y_hat)\n",
    "best_fit = record[idx]\n",
    "print(len(best_fit))\n",
    "plt.plot(range(96), target, label=\"target\")\n",
    "plt.plot(range(96), best_fit, label=\"generated\")\n",
    "plt.legend()\n",
    "# plt.savefig(\"loggings/pv_gen.png\")\n",
    "\n",
    "# print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import autocor, cdf, psd, ws_dist, cor_dist, dtw_dist\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fn_target = cdf(target)\n",
    "fn_fit = cdf(best_fit)\n",
    "x = np.linspace(0,180,300)\n",
    "\n",
    "atc_tgt, freq_tgt  = psd(target)\n",
    "atc_best, freq_best= psd(best_fit)\n",
    "atc_tgt = autocor(target, lags=48, plot=False)\n",
    "atc_best = autocor(best_fit, lags=48, plot=False)\n",
    "fig, ax = plt.subplots()\n",
    "ax.step(x, fn_target(x), label=\"target\")\n",
    "ax.step(x, fn_fit(x), label=\"generated\")\n",
    "ax.plot(freq_tgt, atc_tgt, label=\"target\")\n",
    "ax.plot(freq_best, atc_best, label=\"generated\")\n",
    "# ax.plot(range(len(atc_tgt)), atc_tgt, label=\"target\")\n",
    "# ax.plot(range(len(atc_tgt)), atc_best, label=\"generated\")\n",
    "ax.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c5475bcc71fc973f16978f94c40d216cf18e9eee2007cd0baa59bbad62bf8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
